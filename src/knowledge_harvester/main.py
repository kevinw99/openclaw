"""CLI å…¥å£ - çŸ¥è¯†æ”¶å‰²æœº"""

import argparse
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from knowledge_harvester.config import Config
from knowledge_harvester.storage import Storage
from knowledge_harvester.adapters.chatgpt import ChatGPTAdapter


def _get_config(args) -> Config:
    config = Config()
    if hasattr(args, "output") and args.output:
        config.output_root = args.output
    return config


def _run_extraction(storage, adapter, platform, source="", incremental=False,
                    skip_compat_check=False):
    """é€šç”¨æå–é€»è¾‘ (æ”¯æŒå¢é‡æ¨¡å¼)"""
    # å…¼å®¹æ€§æ£€æŸ¥
    if not skip_compat_check:
        warnings = adapter.check_compatibility()
        if warnings:
            print("âš  å…¼å®¹æ€§è­¦å‘Š:")
            for w in warnings:
                print(f"  - {w}")
            print()

    state = storage.load_state(platform) if incremental else {"last_run": "", "conversations": {}}
    known_ids = set(state.get("conversations", {}).keys()) if incremental else set()

    if incremental:
        print(f"å¢é‡æ¨¡å¼: å·²çŸ¥ {len(known_ids)} æ®µå¯¹è¯")
        if state.get("last_run"):
            print(f"ä¸Šæ¬¡æå–: {state['last_run']}")

    count = 0
    skipped = 0
    for conversation in adapter.extract(source):
        if incremental and not storage.is_conversation_changed(platform, conversation):
            skipped += 1
            continue

        storage.save_conversation(conversation)
        storage.update_state_for_conversation(state, conversation)
        count += 1
        print(f"  âœ“ [{count}] {conversation.title[:50]} ({conversation.message_count} msgs)")

    if incremental:
        storage.save_state(platform, state)

    print("-" * 60)
    print(f"å®Œæˆ! å¯¼å…¥ {count} æ®µå¯¹è¯" + (f", è·³è¿‡ {skipped} æ®µæœªå˜åŒ–" if skipped else ""))
    return count


def cmd_import_chatgpt(args):
    """å¯¼å…¥ ChatGPT å¯¼å‡ºæ•°æ®"""
    config = _get_config(args)
    storage = Storage(config)
    adapter = ChatGPTAdapter()

    print("=" * 60)
    print("çŸ¥è¯†æ”¶å‰²æœº - å¯¼å…¥ ChatGPT")
    print("=" * 60)
    print(f"æ•°æ®æº: {args.source}")
    print(f"è¾“å‡ºç›®å½•: {config.output_dir}")
    print("-" * 60)

    _run_extraction(storage, adapter, "chatgpt", source=args.source,
                    incremental=getattr(args, "incremental", False))


def cmd_scrape_grok(args):
    """ä» Grok ç½‘é¡µæå–å¯¹è¯"""
    from knowledge_harvester.adapters.grok import GrokAdapter
    from knowledge_harvester.browser_client import BrowserClient

    config = _get_config(args)
    storage = Storage(config)
    browser = BrowserClient(base_url=args.browser_url, profile=args.profile)
    adapter = GrokAdapter(browser)

    print("=" * 60)
    print("çŸ¥è¯†æ”¶å‰²æœº - æå– Grok å¯¹è¯")
    print("=" * 60)
    print(f"æµè§ˆå™¨: {args.browser_url} (profile: {args.profile})")
    print(f"è¾“å‡ºç›®å½•: {config.output_dir}")
    print("-" * 60)

    _run_extraction(storage, adapter, "grok",
                    incremental=getattr(args, "incremental", False))


def cmd_scrape_doubao(args):
    """ä»è±†åŒ…ç½‘é¡µæå–å¯¹è¯"""
    from knowledge_harvester.adapters.doubao import DoubaoAdapter
    from knowledge_harvester.browser_client import BrowserClient

    config = _get_config(args)
    storage = Storage(config)
    browser = BrowserClient(base_url=args.browser_url, profile=args.profile)
    adapter = DoubaoAdapter(browser)

    print("=" * 60)
    print("çŸ¥è¯†æ”¶å‰²æœº - æå–è±†åŒ…å¯¹è¯")
    print("=" * 60)
    print(f"æµè§ˆå™¨: {args.browser_url} (profile: {args.profile})")
    print(f"è¾“å‡ºç›®å½•: {config.output_dir}")
    print("-" * 60)

    _run_extraction(storage, adapter, "doubao",
                    incremental=getattr(args, "incremental", False))


def cmd_extract_wechat(args):
    """æå–å¾®ä¿¡å¯¹è¯"""
    from knowledge_harvester.adapters.wechat import WeChatAdapter

    config = _get_config(args)
    storage = Storage(config)

    db_key = args.key or ""
    if args.key_file:
        db_key = Path(args.key_file).read_text().strip()

    adapter = WeChatAdapter(db_key=db_key, data_dir=args.data_dir or "")

    print("=" * 60)
    print("çŸ¥è¯†æ”¶å‰²æœº - æå–å¾®ä¿¡å¯¹è¯")
    print("=" * 60)
    print(f"å¯†é’¥: {'å·²æä¾›' if db_key else 'æœªæä¾› (å°è¯•æ— åŠ å¯†æ¨¡å¼)'}")
    print(f"è¾“å‡ºç›®å½•: {config.output_dir}")
    print("-" * 60)

    _run_extraction(storage, adapter, "wechat", source=args.source or "",
                    incremental=getattr(args, "incremental", False))


def cmd_search(args):
    """æœç´¢å·²å¯¼å…¥çš„å¯¹è¯"""
    from knowledge_harvester.search import SearchEngine

    config = _get_config(args)
    engine = SearchEngine(config)

    query = args.query
    platform = args.platform

    print(f"æœç´¢: \"{query}\"" + (f" (å¹³å°: {platform})" if platform else ""))
    print("-" * 60)

    results = engine.search(query, platform=platform, max_results=args.limit)

    if not results:
        print("æœªæ‰¾åˆ°åŒ¹é…ç»“æœã€‚")
        return

    for r in results:
        ts = r.message.timestamp[:19] if r.message.timestamp else ""
        preview = r.message.content[:120].replace("\n", " ")
        print(f"\n  [{r.platform}] {r.title[:40]}")
        print(f"  {r.message.role:9s} | {ts} | {preview}")

    print(f"\nå…± {len(results)} æ¡ç»“æœ")


def cmd_list(args):
    """åˆ—å‡ºå·²å¯¼å…¥çš„å¯¹è¯"""
    config = _get_config(args)
    storage = Storage(config)

    platforms = storage.list_platforms()
    if not platforms:
        print("æš‚æ— å·²å¯¼å…¥çš„å¯¹è¯ã€‚")
        return

    for platform in platforms:
        conversations = storage.list_conversations(platform)
        print(f"\n[{platform}] {len(conversations)} æ®µå¯¹è¯")
        for conv in conversations:
            title = conv.get("title", "(æ— æ ‡é¢˜)")[:50]
            msg_count = conv.get("message_count", 0)
            print(f"  {conv['id'][:8]}... | {title} | {msg_count} msgs")


def cmd_view(args):
    """æŸ¥çœ‹å®Œæ•´å¯¹è¯"""
    import json as _json
    config = _get_config(args)
    storage = Storage(config)

    query = args.conversation.lower()
    limit = args.limit

    # Search across all platforms for matching conversation
    platforms = storage.list_platforms()
    matches = []
    for platform in platforms:
        for conv in storage.list_conversations(platform):
            conv_id = conv["id"]
            title = conv.get("title", "")
            # Match by ID prefix or title substring
            if (query in conv_id.lower() or query in title.lower()):
                matches.append((platform, conv))

    if not matches:
        print(f"æœªæ‰¾åˆ°åŒ¹é… \"{args.conversation}\" çš„å¯¹è¯ã€‚")
        print("æç¤º: ä½¿ç”¨ 'list' å‘½ä»¤æŸ¥çœ‹æ‰€æœ‰å¯¹è¯, æˆ– 'search' æœç´¢æ¶ˆæ¯å†…å®¹ã€‚")
        return

    if len(matches) > 1 and not args.all:
        print(f"æ‰¾åˆ° {len(matches)} æ®µåŒ¹é…çš„å¯¹è¯:")
        for platform, conv in matches[:20]:
            title = conv.get("title", "(æ— æ ‡é¢˜)")[:50]
            msg_count = conv.get("message_count", 0)
            print(f"  [{platform}] {conv['id'][:30]}... | {title} | {msg_count} msgs")
        if len(matches) > 20:
            print(f"  ... è¿˜æœ‰ {len(matches) - 20} æ®µ")
        print("\nè¯·ä½¿ç”¨æ›´å…·ä½“çš„åç§°, æˆ–åŠ  --all æŸ¥çœ‹æ‰€æœ‰åŒ¹é…ã€‚")
        return

    for platform, conv in matches[:5] if not args.all else matches:
        conv_id = conv["id"]
        title = conv.get("title", "(æ— æ ‡é¢˜)")
        msg_count = conv.get("message_count", 0)

        print(f"\n{'=' * 60}")
        print(f"[{platform}] {title}")
        print(f"ID: {conv_id} | {msg_count} æ¡æ¶ˆæ¯")
        print(f"{'=' * 60}")

        path = config.conversation_path(platform, conv_id)
        if not path.exists():
            print("  (æ–‡ä»¶ä¸å­˜åœ¨)")
            continue

        shown = 0
        with open(path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    data = _json.loads(line)
                except _json.JSONDecodeError:
                    continue

                role = data.get("role", "?")
                ts = data.get("timestamp", "")[:19]
                content = data.get("content", "")

                # Truncate very long messages
                if len(content) > 500:
                    content = content[:500] + "..."

                marker = "â†’" if role == "user" else "â†"
                print(f"\n{marker} [{ts}] {role}")
                print(f"  {content}")

                # æ˜¾ç¤ºåª’ä½“å…ƒæ•°æ®
                media_list = data.get("media", [])
                if media_list:
                    if getattr(args, "media", False):
                        # --media: æ˜¾ç¤ºå®Œæ•´ Tier 1 å…ƒæ•°æ®
                        for m in media_list:
                            parts = [f"    ğŸ“ {m.get('type', '?')}"]
                            if m.get("filename"):
                                parts.append(m["filename"])
                            if m.get("size_bytes"):
                                from knowledge_harvester.adapters.wechat import _format_size
                                parts.append(f"({_format_size(m['size_bytes'])})")
                            print(" ".join(parts))
                            if m.get("original_url"):
                                print(f"      URL: {m['original_url']}")
                            if m.get("description"):
                                desc = m["description"][:200]
                                print(f"      æè¿°: {desc}")
                    else:
                        # é»˜è®¤: ä»…æ˜¾ç¤ºç®€è¦æ¦‚è§ˆ
                        types = [m.get("type", "?") for m in media_list]
                        print(f"    [é™„ä»¶: {', '.join(types)}]")

                shown += 1
                if limit and shown >= limit:
                    remaining = msg_count - shown
                    if remaining > 0:
                        print(f"\n  ... è¿˜æœ‰ {remaining} æ¡æ¶ˆæ¯ (ä½¿ç”¨ --limit 0 æŸ¥çœ‹å…¨éƒ¨)")
                    break


def cmd_stats(args):
    """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
    from knowledge_harvester.search import SearchEngine

    config = _get_config(args)
    engine = SearchEngine(config)

    s = engine.stats()
    if not s["platforms"]:
        print("æš‚æ— å·²å¯¼å…¥çš„å¯¹è¯ã€‚")
        return

    print("=" * 60)
    print("çŸ¥è¯†åº“ç»Ÿè®¡")
    print("=" * 60)

    for plat, data in s["platforms"].items():
        print(f"  {plat}: {data['conversations']} æ®µå¯¹è¯, {data['messages']} æ¡æ¶ˆæ¯")

    print(f"\næ€»è®¡: {s['total_conversations']} æ®µå¯¹è¯, {s['total_messages']} æ¡æ¶ˆæ¯")
    print(f"å¹³å°æ•°: {len(s['platforms'])}")


def main():
    """ä¸»å…¥å£"""
    parser = argparse.ArgumentParser(
        description="çŸ¥è¯†æ”¶å‰²æœº - å¤šå¹³å°å¯¹è¯å†å²æå–ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
æ”¯æŒçš„å¹³å°:
  chatgpt   â€” å®˜æ–¹ JSON å¯¼å‡º (Settings > Data Controls > Export)
  grok      â€” æµè§ˆå™¨è‡ªåŠ¨åŒ– (éœ€è¦ OpenClaw ç½‘å…³)
  doubao    â€” æµè§ˆå™¨è‡ªåŠ¨åŒ– (éœ€è¦ OpenClaw ç½‘å…³)
  wechat    â€” æœ¬åœ° SQLite æ•°æ®åº“ (éœ€è¦è§£å¯†å¯†é’¥)

ç¤ºä¾‹:
  python3 -m knowledge_harvester import-chatgpt ~/Downloads/chatgpt-export.zip
  python3 -m knowledge_harvester scrape-grok
  python3 -m knowledge_harvester search "Python è£…é¥°å™¨"
        """,
    )
    parser.add_argument("--output", "-o", help="è¾“å‡ºç›®å½• (é»˜è®¤: çŸ¥è¯†åº“/conversations)")

    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")

    # å…¬å…±å‚æ•°
    _incremental_help = "å¢é‡æ¨¡å¼: è·³è¿‡æœªå˜åŒ–çš„å¯¹è¯"

    # import-chatgpt
    p_chatgpt = subparsers.add_parser("import-chatgpt", help="å¯¼å…¥ ChatGPT å¯¼å‡ºæ•°æ®")
    p_chatgpt.add_argument("source", help="ChatGPT å¯¼å‡ºçš„ ZIP æˆ– conversations.json è·¯å¾„")
    p_chatgpt.add_argument("--incremental", "-i", action="store_true", help=_incremental_help)

    # scrape-grok
    p_grok = subparsers.add_parser("scrape-grok", help="ä» Grok ç½‘é¡µæå–å¯¹è¯")
    p_grok.add_argument("--browser-url", default="http://127.0.0.1:18791",
                        help="OpenClaw æµè§ˆå™¨æœåŠ¡åœ°å€")
    p_grok.add_argument("--profile", default="chrome", help="æµè§ˆå™¨ profile å")
    p_grok.add_argument("--incremental", "-i", action="store_true", help=_incremental_help)

    # scrape-doubao
    p_doubao = subparsers.add_parser("scrape-doubao", help="ä»è±†åŒ…ç½‘é¡µæå–å¯¹è¯")
    p_doubao.add_argument("--browser-url", default="http://127.0.0.1:18791",
                          help="OpenClaw æµè§ˆå™¨æœåŠ¡åœ°å€")
    p_doubao.add_argument("--profile", default="chrome", help="æµè§ˆå™¨ profile å")
    p_doubao.add_argument("--incremental", "-i", action="store_true", help=_incremental_help)

    # extract-wechat
    p_wechat = subparsers.add_parser("extract-wechat", help="æå–å¾®ä¿¡å¯¹è¯")
    p_wechat.add_argument("--key", help="SQLCipher å¯†é’¥ (64ä½åå…­è¿›åˆ¶)")
    p_wechat.add_argument("--key-file", help="åŒ…å«å¯†é’¥çš„æ–‡ä»¶è·¯å¾„")
    p_wechat.add_argument("--data-dir", help="å¾®ä¿¡æ•°æ®ç›®å½• (é»˜è®¤è‡ªåŠ¨æ£€æµ‹)")
    p_wechat.add_argument("--incremental", "-i", action="store_true", help=_incremental_help)
    p_wechat.add_argument("source", nargs="?", default="",
                          help="æ•°æ®åº“æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„ (é»˜è®¤è‡ªåŠ¨æ£€æµ‹)")

    # search
    p_search = subparsers.add_parser("search", help="æœç´¢å¯¹è¯å†…å®¹")
    p_search.add_argument("query", help="æœç´¢å…³é”®è¯")
    p_search.add_argument("--platform", "-p", help="é™å®šæœç´¢å¹³å°")
    p_search.add_argument("--limit", "-n", type=int, default=20, help="æœ€å¤§ç»“æœæ•°")

    # view
    p_view = subparsers.add_parser("view", help="æŸ¥çœ‹å®Œæ•´å¯¹è¯")
    p_view.add_argument("conversation", help="å¯¹è¯ ID æˆ–æ ‡é¢˜å…³é”®è¯")
    p_view.add_argument("--limit", "-n", type=int, default=100, help="æ˜¾ç¤ºæ¶ˆæ¯æ•° (0=å…¨éƒ¨)")
    p_view.add_argument("--all", "-a", action="store_true", help="æŸ¥çœ‹æ‰€æœ‰åŒ¹é…çš„å¯¹è¯")
    p_view.add_argument("--media", "-m", action="store_true", help="æ˜¾ç¤ºå®Œæ•´åª’ä½“å…ƒæ•°æ® (URL, æè¿°ç­‰)")

    # list
    subparsers.add_parser("list", help="åˆ—å‡ºå·²å¯¼å…¥çš„å¯¹è¯")

    # stats
    subparsers.add_parser("stats", help="æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯")

    args = parser.parse_args()

    commands = {
        "import-chatgpt": cmd_import_chatgpt,
        "scrape-grok": cmd_scrape_grok,
        "scrape-doubao": cmd_scrape_doubao,
        "extract-wechat": cmd_extract_wechat,
        "search": cmd_search,
        "view": cmd_view,
        "list": cmd_list,
        "stats": cmd_stats,
    }

    handler = commands.get(args.command)
    if handler:
        handler(args)
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
